{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import einops\n",
    "class MHA(nn.Module):\n",
    "    def __init__(self,hidden_size,num_heads):\n",
    "        super().__init__()\n",
    "        self.q_l=nn.Linear(hidden_size,hidden_size)\n",
    "        self.k_l=nn.Linear(hidden_size,hidden_size)# group\n",
    "        self.v_l=nn.Linear(hidden_size,hidden_size)# group\n",
    "        self.o_l=nn.Linear(hidden_size,hidden_size)\n",
    "        self.head_dim=hidden_size//num_heads# 头的维度\n",
    "    \n",
    "    def forward(self, hs, mask=None):\n",
    "        bz=hs.shape[0]# 第0维度\n",
    "        q=self.q_l(hs)\n",
    "        k=self.k_l(hs)\n",
    "        v=self.v_l(hs)\n",
    "\n",
    "        q=einops.rearange(q,\"b seq_len (head head_dim) -> b head seq_len  head_dim\")## d 代表每个头的维度\n",
    "        k=einops.rearange(k,\"b seq_len (head head_dim) -> b head seq_len  head_dim\")## d 代表每个头的维度 # group\n",
    "        v=einops.rearange(v,\"b seq_len (head head_dim) -> b head seq_len  head_dim\")## d 代表每个头的维度 # group\n",
    "\n",
    "        # intervalue_repeat\n",
    "        # intervalue_repeat\n",
    "        # intervalue_repeat       \n",
    "        \n",
    "        attention_score=torch.matmul(q,k.transpose(-1,-2)/torch.sqrt(torch.tensor(self.head_dim)))\n",
    "        # b head seq_len seq_len\n",
    "        if mask !=None:\n",
    "            attention_score=attention_score.masked_fill(mask==0,float(\"-inf\"))\n",
    "        # 归一化#对最后一维度的score进行归一化\n",
    "        attention_prob=torch.softmax(attention_score,dim=-1)\n",
    "        # seq_len seq_len @ seq_len head_dim\n",
    "        out=torch.matmul(attention_prob,v)\n",
    "        out=einops.rearrenge(out,\"b head seq_len head_dim -> b seq_len (head head_dim)\")\n",
    "        out_final=self.o_l(out)\n",
    "        return out_final\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from einops import rearrange\n",
    "\n",
    "class MQA(nn.Module):\n",
    "    def __init__(self, hz, num_heads):\n",
    "        super().__init__()\n",
    "        self.q_l=nn.Linear(hz,hz)\n",
    "        self.k_l=nn.Linear(hz,num_heads)\n",
    "        self.v_l=nn.Linear(hz,num_heads)\n",
    "        self.o_l=nn.Linear(hz,hz)\n",
    "        self.head_dim=hz//num_heads\n",
    "\n",
    "    def forward(self, hs, mask=None):\n",
    "        q=self.q_l(hs)\n",
    "        k=self.k_l(hs)\n",
    "        v=self.v_l(hs)\n",
    "\n",
    "        q=einops.rearrange(q,\"b seq_len (head head_dim) -> b head seq_len head_dim\")\n",
    "        k=einops.rearrange(k,\"b seq_len (head head_dim) -> b 1 seq_len head_dim\")\n",
    "        v=einops.rearrange(v,\"b seq_len (head head_dim) -> b 1 seq_len head_dim\")\n",
    "        k=k.expand(-1,self.num_heads,-1,-1)\n",
    "        v=v.expand(-1,self.num_heads,-1,-1)\n",
    "        #  b h s d @ b 1 s d = b h s s\n",
    "        attention_score=torch.malmul(q,k.transpose(-1,-2))/torch.sqrt(torch.tensor(self.head_dim))\n",
    "        # if mask\n",
    "        if mask !=None:\n",
    "            attention_score=attention_score.masked_fill(mask==0,float(\"-inf\"))\n",
    "        attention_prob=torch.softmax(attention_score,dim=-1)\n",
    "        out= torch.matmul(attention_prob,v)\n",
    "        out=einops.rearrenge(out,\"b head seq_len head_dim -> b seq_len (head head_dim)\")\n",
    "        out_final=self.o_l(out)\n",
    "        return out_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from einops import rearrange\n",
    "\n",
    "class MHA(nn.Module):\n",
    "    def __init__(self,hz,num_heads):\n",
    "        super.__init__()\n",
    "        self.head_dim=hz//num_heads\n",
    "        self.q_l=nn.Linear(hz,hz)\n",
    "        self.k_l=nn.Linear(hz,hz)\n",
    "        self.v_l=nn.Linear(hz,hz)\n",
    "        self.o_l=nn.Linear(hz,hz)\n",
    "\n",
    "    def forward(self,hidden_state, mask=None):\n",
    "        q=self.q_l(hidden_state)\n",
    "        k=self.k_l(hidden_state)\n",
    "        v=self.v_l(hidden_state)\n",
    "        # o=self.o_l(hidden_state)\n",
    "\n",
    "        q=einops.rearrange(q,\"b seq_len (head head_dim) -> b head seq_len head_dim\")\n",
    "        k=einops.rearrange(k,\"b seq_len (head head_dim) -> b head seq_len head_dim\")\n",
    "        v=einops.rearrange(v,\"b seq_len (head head_dim) -> b head seq_len head_dim\")\n",
    "\n",
    "        attention_score=torch.malmut(q,k.transport(-1,-2))/torch.sqrt(self.head_dim)\n",
    "        # b h s dim @ b h dim s = b h s s\n",
    "        if mask==None:\n",
    "            attention_score=attention_score.mask_filled(mask==0,float('-inf'))\n",
    "        attention_prob=torch.softmax(attention_score,dim=-1)\n",
    "        out=torch.matmul(attention_prob,v)\n",
    "        out= einops.rearrenge(out,\"b head seq_len head_dim -> b seq_len (head head_dim)\")\n",
    "        out= self.o_l(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(self,model,inputs,return_outputs=False,num_item_in_batch=None):\n",
    "    prompt_ids,prompt_mask=inputs['input_ids'],inputs['prompt_mask']\n",
    "    completion_ids,completion_mask=inputs['completion_ids'],inputs[\"completion_mask\"]\n",
    "    input_ids=torch.cat([prompt_ids,completion_ids],dim=1)\n",
    "    attention_mask= torch.cat([prompt_mask,completion_mask])\n",
    "    logits_to_keep =completion_ids.size(1) #只需要计算completion 的token的loss\n",
    "    per_token_logps= self._get_per_token_logps(model,input_ids,attention_mask, logits_to_keep)\n",
    "    ref_per_token_logps=inputs[\"ref_per_token_logps\"]\n",
    "    #Loss = E[min(ratio * advantage, clip(ratio, 1-ε, 1+ε) * advantage)]\n",
    "    per_token_kl= torch.exp(ref_per_token_logps-per_token_logps)-(ref_per_token_logps-per_token_logps)-1\n",
    "    advantages=inputs[\"advantages\"]\n",
    "    # x-x.detach\n",
    "    # log_ratio = per_token_logps - per_token_logps.detach()  # log(π_new / π_old)\n",
    "    # ratio = torch.exp(log_ratio)  # π_new / π_old\n",
    "    per_token_loss=torch.exp(per_token_logps-per_token_logps.detach())* advantages.unsqueeze(-1)\n",
    "    per_token_loss=-(per_token_loss-self.beta*per_token_kl)\n",
    "    loss=((per_token_loss * completion_mask).sum(dim=1)/completion_mask.sum(dim=1)).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrenge\n",
    "def compute_loss_trl(self, model,inputs,group,rewards_per_func=[], return_outputs=False,num_item_in_batch=None):\n",
    "    rewards=rewards_per_func.sum(dim=1)\n",
    "\n",
    "    per_token_logps=self._get_per_token_logps(model,inputs,attention_mask,logits_to_keep)\n",
    "    ref_per_token_logps=inputs[\"ref_per_token_logps\"]\n",
    "    # compute grouped-wise rewards\n",
    "    mean_group_rewards=rearrange(rewards,\"(b g) -> b g\",g=self.num_generation).mean(dim=1)# 对组做平均\n",
    "    std_group_rewards=rearrange(rewards,'(b g) -> b g',g=self.num_generation).std(dim=1)\n",
    "    ## 已经对组进行了处理，但是需要进行复制广播\n",
    "\n",
    "    # =# Normalize the rewards to compute the advantages​\n",
    "    mean_grouped_rewards = mean_grouped_rewards.repeat_interleave(self.num_generations, dim=0)​# 还是标量，进行增广\n",
    "    std_grouped_rewards = std_grouped_rewards.repeat_interleave(self.num_generations, dim=0)# 标量增广\n",
    "    # pi/pi_old - log(pi/pi_old)-# 指数操作\n",
    "    per_token_kl=torch.exp(ref_per_token_logps-per_token_logps)-(ref_per_token_logps-per_token_logps)-1\n",
    "    advantages=(rewards-mean_group_rewards)/(std_group_rewards+1e-4)\n",
    "    coff_1=torch.exp(per_token_logps-per_token_logps.detach())\n",
    "    coff_2=torch.clamp(coff_1,1-self.epsilon,1+self.epsilon)# 裁剪\n",
    "    advantage=rearrenge(advantages,'(b g)->(b g) 1')# 增广\n",
    "    # coff_1=  per_token_logps-per_token_logps.detach\n",
    "    \n",
    "    per_token_loss= min(coff_1*advantage,coff_2*advantage)\n",
    "    # (b g) sep_len\n",
    "    per_token_loss=-(per_token_loss-self.beta*per_token_kl)\n",
    "    # 对每个token 去均值loss\n",
    "    loss=((per_token_loss*completion_mask).sum(dim=1)/self.completion_mask.sum(dim=1)).mean()\n",
    "    return loss \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from einops import rearrenge\n",
    "def compute_loss(self, input,group,rewards_func):\n",
    "    rewards=rewards_func.sum(dim=1)# b g seq_len func\n",
    "    \n",
    "    mean_group_rewards=rearrenge(rewards,\"(b g)\")\n",
    "    str_group_rewards=rearrenge()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import einops\n",
    "from einops import rearrange\n",
    "def compute_loss(self,model,inputs,mask,rewards_func):\n",
    "    completion_mask=torch.cat([inputs[\"prompt_mask\"],inputs[\"completion_mask\"]],dim=1)\n",
    "    rewards= rewards_func.sum(dim=1)# b* g 标量\n",
    "    per_token_logps=self._get_per_token_logps(model,inputs,mask,logit_to_keep=True)\n",
    "    ref_per_token_logps=inputs[\"ref_per_token_logps\"]\n",
    "\n",
    "    mean_group_rewards=rearrange(rewards,\"(b g) -> b g\",g=self.num_generation)\\\n",
    "        .mean(dim=1) \\\n",
    "        .repeat_interleave(self.num_generation,dim=0)\n",
    "    std_group_rewards=rearrange(rewards,\"(b g) -> b g\",g=self.num_generation)\\\n",
    "        .std(dim=1) \\\n",
    "        .repeat_interleave(self.num_generation,dim=0)\n",
    "    advantages=(rewards-mean_group_rewards)/(std_group_rewards+1e-4)   \n",
    "    per_token_kl=torch.exp(ref_per_token_logps-per_token_logps)-(ref_per_token_logps-per_token_logps)-1\n",
    "    # (per_token_logps-per_token_logps.detach())\n",
    "    # -((pi/pi_old,clamp(pi/pi_old)-self.beta*per_token_kl))\n",
    "    pi_pi_old=torch.exp(per_token_logps-per_token_logps.detach())\n",
    "    per_token_loss=torch.min(pi_pi_old*advantages.unsqueeze(1),torch.clamp(pi_pi_old,1-self.epsilon,1+self.epsilon)*advantages.unsqueeze(1))\n",
    "    per_token_loss=-(per_token_loss-self.beta*per_token_kl)\n",
    "    loss=(per_token_loss*completion_mask).sum(dim=1)/completion_mask.sum(dim=1).mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "videochat-r1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
