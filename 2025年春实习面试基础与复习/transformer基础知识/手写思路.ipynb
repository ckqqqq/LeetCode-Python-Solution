{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "ORM（Outcome Reward Model）是在生成模型中，对生成结果整体打分评估。\n",
    "PRM（Process Reward Model）是在生成过程中，分步骤对每一步进行打分的更细粒度奖励模型。\n",
    "RM（Process-based Verifier Model 或Process Reward Model，过程奖励模型）\n",
    "\n",
    "在论文中，研究团队详细解释了一种 PRM（Process-based Verifier Model 或Process Reward Model，过程奖励模型）作为和 LLM（大语言模型）对弈的对手，它的推理模式和其效果。PRM 是在思维链的过程中给出奖励（打分）的模型，过程奖励模型。它是一个单独被训练出来的模型，它拥有两个能力，一个是将问题拆成一步一步的思维链的能力；另一个是对大模型生成的每一步进行打分，并在结果不够理想时让大模型重新生成结果。它不仅可以评判每一个具体回答的优与劣，也可以评判在整个思维链过程中最佳的流程。\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 思路\n",
    "* 一般来说，简历中写什么去手写什么（错误，最基本的得会写\n",
    "  ）\n",
    "* 简历中写"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
