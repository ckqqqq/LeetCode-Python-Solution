{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Tensor type unknown to einops <class 'str'>",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m o_matmul = torch.matmul(q, k.transpose(-\u001b[32m2\u001b[39m, -\u001b[32m1\u001b[39m))  \u001b[38;5;66;03m#einsum('b h s d, b h s d -> b h s s', q, k) 但这实际上会计算每个位置s的d维的点积，导致结果形状为b h s s\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# 使用einops.einsum\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m k_t=\u001b[43mrearrange\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mb h s d -> b h d s\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m o_einsum = einsum(\u001b[33m'\u001b[39m\u001b[33mb h s1 d, b h d s2 -> b h s1 s2\u001b[39m\u001b[33m'\u001b[39m, q, k_t)\n\u001b[32m     13\u001b[39m x, y, z = torch.randn(\u001b[32m3\u001b[39m, \u001b[32m20\u001b[39m, \u001b[32m20\u001b[39m, \u001b[32m20\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\TOOL\\Anaconda\\Anaconda_root\\envs\\torchok\\Lib\\site-packages\\einops\\einops.py:600\u001b[39m, in \u001b[36mrearrange\u001b[39m\u001b[34m(tensor, pattern, **axes_lengths)\u001b[39m\n\u001b[32m    545\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrearrange\u001b[39m(tensor: Union[Tensor, List[Tensor]], pattern: \u001b[38;5;28mstr\u001b[39m, **axes_lengths: Size) -> Tensor:\n\u001b[32m    546\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    547\u001b[39m \u001b[33;03m    einops.rearrange is a reader-friendly smart element reordering for multidimensional tensors.\u001b[39;00m\n\u001b[32m    548\u001b[39m \u001b[33;03m    This operation includes functionality of transpose (axes permutation), reshape (view), squeeze, unsqueeze,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    598\u001b[39m \n\u001b[32m    599\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m600\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrearrange\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43maxes_lengths\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\TOOL\\Anaconda\\Anaconda_root\\envs\\torchok\\Lib\\site-packages\\einops\\einops.py:527\u001b[39m, in \u001b[36mreduce\u001b[39m\u001b[34m(tensor, pattern, reduction, **axes_lengths)\u001b[39m\n\u001b[32m    525\u001b[39m     tensor = backend.stack_on_zeroth_dimension(tensor)\n\u001b[32m    526\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m527\u001b[39m     backend = \u001b[43mget_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    529\u001b[39m hashable_axes_lengths = \u001b[38;5;28mtuple\u001b[39m(axes_lengths.items())\n\u001b[32m    530\u001b[39m shape = backend.shape(tensor)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\TOOL\\Anaconda\\Anaconda_root\\envs\\torchok\\Lib\\site-packages\\einops\\_backends.py:59\u001b[39m, in \u001b[36mget_backend\u001b[39m\u001b[34m(tensor)\u001b[39m\n\u001b[32m     56\u001b[39m                 _type2backend[_type] = backend\n\u001b[32m     57\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m backend\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mTensor type unknown to einops \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\u001b[38;5;28mtype\u001b[39m(tensor)))\n",
      "\u001b[31mRuntimeError\u001b[39m: Tensor type unknown to einops <class 'str'>"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from einops import einsum,rearrange\n",
    "b, h, s, d = 2, 3, 4, 5\n",
    "\n",
    "q = torch.randn(b, h, s, d)\n",
    "\n",
    "k = torch.randn(b, h, s, d)\n",
    "o_matmul = torch.matmul(q, k.transpose(-2, -1))  #einsum('b h s d, b h s d -> b h s s', q, k) 但这实际上会计算每个位置s的d维的点积，导致结果形状为b h s s\n",
    "# 使用einops.einsum\n",
    "k_t=rearrange('b h s d -> b h d s',k)\n",
    "o_einsum = einsum('b h s1 d, b h d s2 -> b h s1 s2', q, k_t)\n",
    "x, y, z = torch.randn(3, 20, 20, 20)\n",
    "# output = einsum(x, y, z, \"a b c, c b d, a g k -> a b k\")\n",
    "\n",
    "# 检查是否相同\n",
    "\n",
    "# print(torch.allclose(o_einsum, o_matmul))  # 应该输出True\n",
    "print(o_matmul.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 32, 4, 16])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "i_a = torch.randn(16, 32, 4, 8)\n",
    "i_b = torch.randn(16, 32, 8, 16)\n",
    "\n",
    "out = torch.einsum('b h i j, b h j d -> b h i d', i_a, i_b)\n",
    "print(out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 手撕 MHA, 多头注意力，注意的点是投影矩阵\n",
    "# 使用 einops 这样好得多\n",
    "from torch import nn\n",
    "import torch\n",
    "import einops\n",
    "#  einops\n",
    "class MHA(torch.nn.Module):# 注意是    Module\n",
    "    def __init__(self,hidden_size,head_num):\n",
    "        super().__init__()\n",
    "        assert hidden_size% head_num==0\n",
    "        self.hidden_size=hidden_size\n",
    "        self.head_num=head_num\n",
    "        self.q_linear=torch.nn.Linear(hidden_size,hidden_size)\n",
    "        self.k_linear=torch.nn.Linear(hidden_size,hidden_size)\n",
    "        self.v_linear=torch.nn.Linear(hidden_size,hidden_size)\n",
    "        self.o_linear=torch.nn.Linear(hidden_size,hidden_size)\n",
    "    def forward(self,x,mask=None):# 注意不要把向量写错了\n",
    "        head_num=self.head_num\n",
    "        q=self.q_linear(x)\n",
    "        k=self.k_linear(x)\n",
    "        v=self.v_linear(x)\n",
    "        q=einops.rearrange(q,pattern=\"b s (h d) -> b h s d\",h=head_num)# d=head dim\n",
    "        k=einops.rearrange(k,pattern='b s (h d) -> b h s d',h=head_num)\n",
    "        v=einops.rearrange(v,pattern='b s (h d) -> b h s d',h=head_num)\n",
    "        atten_score=torch.matmul(q,k.transpose(-1,-2))/torch.sqrt(torch.tensor(self.hidden_size))# 注意 需要转为tensor才能 sqrt\n",
    "        if mask!=None:# b s s\n",
    "            mask = mask.unsqueeze(1)  # 在第一个维度上增加头维度  b 1 s s\n",
    "            atten_score = atten_score.masked_fill(mask == 0, float('-inf'))\n",
    "        atten_probs=torch.softmax(input=atten_score,dim=-1)\n",
    "        # o= einops.einsum('b h s1 s2, b h s2 d -> b h s1 d',atten_probs,v)\n",
    "        o= torch.matmul(atten_probs,v)# 矩阵乘法还是matmul最舒服，注意不符合交换律哦\n",
    "        # 而且注意是 \n",
    "        o= einops.rearrange(o,pattern='b h s d -> b s (h d)',h=head_num)\n",
    "        return self.o_linear(o)\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"d:\\TOOL\\Anaconda\\Anaconda_root\\envs\\torchok\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"d:\\TOOL\\Anaconda\\Anaconda_root\\envs\\torchok\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"d:\\TOOL\\Anaconda\\Anaconda_root\\envs\\torchok\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"d:\\TOOL\\Anaconda\\Anaconda_root\\envs\\torchok\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"d:\\TOOL\\Anaconda\\Anaconda_root\\envs\\torchok\\Lib\\asyncio\\base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"d:\\TOOL\\Anaconda\\Anaconda_root\\envs\\torchok\\Lib\\asyncio\\base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "  File \"d:\\TOOL\\Anaconda\\Anaconda_root\\envs\\torchok\\Lib\\asyncio\\events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"d:\\TOOL\\Anaconda\\Anaconda_root\\envs\\torchok\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"d:\\TOOL\\Anaconda\\Anaconda_root\\envs\\torchok\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"d:\\TOOL\\Anaconda\\Anaconda_root\\envs\\torchok\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"d:\\TOOL\\Anaconda\\Anaconda_root\\envs\\torchok\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"d:\\TOOL\\Anaconda\\Anaconda_root\\envs\\torchok\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"d:\\TOOL\\Anaconda\\Anaconda_root\\envs\\torchok\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"d:\\TOOL\\Anaconda\\Anaconda_root\\envs\\torchok\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"d:\\TOOL\\Anaconda\\Anaconda_root\\envs\\torchok\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3047, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"d:\\TOOL\\Anaconda\\Anaconda_root\\envs\\torchok\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3102, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"d:\\TOOL\\Anaconda\\Anaconda_root\\envs\\torchok\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"d:\\TOOL\\Anaconda\\Anaconda_root\\envs\\torchok\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3306, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"d:\\TOOL\\Anaconda\\Anaconda_root\\envs\\torchok\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3489, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"d:\\TOOL\\Anaconda\\Anaconda_root\\envs\\torchok\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3549, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\qiker chen\\AppData\\Local\\Temp\\ipykernel_17056\\3974987868.py\", line 25, in <module>\n",
      "    test_mha()\n",
      "  File \"C:\\Users\\qiker chen\\AppData\\Local\\Temp\\ipykernel_17056\\3974987868.py\", line 8, in test_mha\n",
      "    model = MHA(hidden_size, head_num)\n",
      "  File \"C:\\Users\\qiker chen\\AppData\\Local\\Temp\\ipykernel_17056\\3727921144.py\", line 13, in __init__\n",
      "    self.q_linear=torch.nn.Linear(hidden_size,hidden_size)\n",
      "  File \"d:\\TOOL\\Anaconda\\Anaconda_root\\envs\\torchok\\Lib\\site-packages\\torch\\nn\\modules\\linear.py\", line 103, in __init__\n",
      "    self.reset_parameters()\n",
      "  File \"d:\\TOOL\\Anaconda\\Anaconda_root\\envs\\torchok\\Lib\\site-packages\\torch\\nn\\modules\\linear.py\", line 109, in reset_parameters\n",
      "    init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
      "  File \"d:\\TOOL\\Anaconda\\Anaconda_root\\envs\\torchok\\Lib\\site-packages\\torch\\nn\\init.py\", line 459, in kaiming_uniform_\n",
      "    return tensor.uniform_(-bound, bound, generator=generator)\n",
      "d:\\TOOL\\Anaconda\\Anaconda_root\\envs\\torchok\\Lib\\site-packages\\torch\\nn\\init.py:459: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  return tensor.uniform_(-bound, bound, generator=generator)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有测试通过！\n"
     ]
    }
   ],
   "source": [
    "def test_mha():\n",
    "    hidden_size = 64\n",
    "    head_num = 8\n",
    "    batch_size = 2\n",
    "    seq_len = 10\n",
    "    \n",
    "    # 初始化模型\n",
    "    model = MHA(hidden_size, head_num)\n",
    "    \n",
    "    # 测试正常输入\n",
    "    x = torch.randn(batch_size, seq_len, hidden_size)\n",
    "    output = model(x)\n",
    "    assert output.shape == (batch_size, seq_len, hidden_size), \"输出形状错误\"\n",
    "    \n",
    "    # 测试掩码 # 注意掩码是 B S S 哦\n",
    "    mask = torch.ones(batch_size, seq_len, seq_len)\n",
    "    mask[:, :, 5:] = 0  # 屏蔽后5个位置\n",
    "    masked_output = model(x, mask)\n",
    "    \n",
    "    # 验证输出是否不同（简单检查）\n",
    "    assert not torch.allclose(output, masked_output), \"掩码未生效\"\n",
    "    \n",
    "    print(\"所有测试通过！\")\n",
    "\n",
    "test_mha()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchok",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
